{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcurmei/Documents/recsys/recsys-eval/experiments/run_utils.py:16: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import tqdm.autonotebook\n",
      "/Users/mcurmei/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import run_utils\n",
    "\n",
    "sys.path.append('../') \n",
    "import reclab\n",
    "\n",
    "from reclab.recommenders import SLIM, EASE\n",
    "from reclab.recommenders import KNNRecommender\n",
    "from reclab.recommenders import LibFM\n",
    "from reclab.recommenders import Llorma\n",
    "from reclab import data_utils\n",
    "\n",
    "sys.path.append('../tests') \n",
    "import utils\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for metrics\n",
    "\n",
    "def compute_PREC_REC_MAP_NDCG_MRR(N, users, recs, test_ratings):\n",
    "    assert recs.shape[1] >= N\n",
    "    metrics = ['PREC', 'REC', 'MAP', 'NDCG', 'MRR']\n",
    "    res = {key:[] for key in metrics}\n",
    "    test_rating_matrix = np.array(list(test_ratings.keys()))\n",
    "    for user_id, rec in zip(users, recs):\n",
    "        test_matrix = test_rating_matrix[test_rating_matrix[:,0]==user_id,1]\n",
    "        prec, recall, ncdg = precision_recall_ndcg_at_k(N, rec[:N], test_matrix)\n",
    "        MAP, mrr, ncdg = map_mrr_ndcg(rec[:N], test_matrix)\n",
    "        res['PREC'].append(prec)\n",
    "        res['REC'].append(recall)\n",
    "        res['NDCG'].append(ncdg)\n",
    "        res['MAP'].append(MAP)\n",
    "        res['MRR'].append(mrr)\n",
    "    return {key:np.mean(res[key]) for key in metrics}\n",
    "\n",
    "## From \"A troubling analysis\"... \n",
    "### https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation/blob/861eafeaba2943458adec22469b147ec492784b6/Conferences/IJCAI/NeuRec_github/eval.py\n",
    "\n",
    "def precision_recall_ndcg_at_k(k, rankedlist, test_matrix):\n",
    "    idcg_k = 0\n",
    "    dcg_k = 0\n",
    "    n_k = k if len(test_matrix) > k else len(test_matrix)\n",
    "    if n_k == 0:\n",
    "        return 0, 0, 0\n",
    "    for i in range(n_k):\n",
    "        idcg_k += 1 / np.log2(i + 2)\n",
    "\n",
    "    b1 = rankedlist\n",
    "    b2 = test_matrix\n",
    "    s2 = set(b2)\n",
    "    hits = [(idx, val) for idx, val in enumerate(b1) if val in s2]\n",
    "    count = len(hits)\n",
    "\n",
    "    for c in range(count):\n",
    "        dcg_k += 1 / np.log2(hits[c][0] + 2)\n",
    "\n",
    "    return float(count / k), float(count / len(test_matrix)), float(dcg_k / idcg_k)\n",
    "\n",
    "\n",
    "def map_mrr_ndcg(rankedlist, test_matrix):\n",
    "    ap = 0\n",
    "    map = 0\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    mrr = 0\n",
    "    if len(test_matrix) == 0:\n",
    "        return 0, 0, 0\n",
    "    for i in range(len(test_matrix)):\n",
    "        idcg += 1 / np.log2(i + 2)\n",
    "\n",
    "    b1 = rankedlist\n",
    "    b2 = test_matrix\n",
    "    s2 = set(b2)\n",
    "    hits = [(idx, val) for idx, val in enumerate(b1) if val in s2]\n",
    "    count = len(hits)\n",
    "\n",
    "    for c in range(count):\n",
    "        ap += (c + 1) / (hits[c][0] + 1)\n",
    "        dcg += 1 / np.log2(hits[c][0] + 2)\n",
    "\n",
    "    if count != 0:\n",
    "        mrr = 1 / (hits[0][0] + 1)\n",
    "\n",
    "    if count != 0:\n",
    "        map = ap / count\n",
    "\n",
    "    return map, mrr, float(dcg / idcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k]\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "\n",
    "def recall_at_k(r, k, all_pos_num):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum(r) / all_pos_num\n",
    "\n",
    "def average_precision(r,cut):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r)\n",
    "    out = [precision_at_k(r, k + 1) for k in range(cut) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.sum(out)/float(min(cut, np.sum(r)))\n",
    "\n",
    "def test_one_user(recs, training_items, user_pos_test):\n",
    "    if len(user_pos_test) == 0:\n",
    "        return None\n",
    "    r = []\n",
    "    for i in recs:\n",
    "        if i in user_pos_test:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    \n",
    "    recall_20 = recall_at_k(r, 20, len(user_pos_test))\n",
    "    recall_40 = recall_at_k(r, 40, len(user_pos_test))\n",
    "    recall_60 = recall_at_k(r, 60, len(user_pos_test))\n",
    "    recall_80 = recall_at_k(r, 80, len(user_pos_test))\n",
    "    recall_100 = recall_at_k(r, 100, len(user_pos_test))\n",
    "\n",
    "    ap_20 = average_precision(r,20)\n",
    "    ap_40 = average_precision(r, 40)\n",
    "    ap_60 = average_precision(r, 60)\n",
    "    ap_80 = average_precision(r, 80)\n",
    "    ap_100 = average_precision(r, 100)\n",
    "\n",
    "\n",
    "    return np.array([recall_20,recall_40,recall_60,recall_80,recall_100, ap_20,ap_40,ap_60,ap_80,ap_100])\n",
    "\n",
    "\n",
    "def test(recs, train_ratings, test_ratings, users):\n",
    "    train_items = collections.defaultdict(list)\n",
    "    for uid, iid in train_ratings:\n",
    "        train_items[uid].append(iid)\n",
    "\n",
    "    test_items = collections.defaultdict(list) \n",
    "    for uid, iid in test_ratings:\n",
    "        test_items[uid].append(iid)\n",
    "    result = np.array([0.] * 10)\n",
    "    tot_num = 0\n",
    "    for user_id, rec in zip(users, recs):\n",
    "        res = test_one_user(rec, train_items[user_id], test_items[user_id])\n",
    "        if res is not None:\n",
    "            result += res\n",
    "            tot_num += 1\n",
    "\n",
    "    ret = result / tot_num\n",
    "    return list(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIM\n",
    "\n",
    "In \"A troubling analysis\" (https://arxiv.org/pdf/1911.07698.pdf) Table 12, SLIM achieves the following results on ML 1M.\n",
    "\n",
    "\n",
    "| PREC@5   | REC@5   | MAP@5   | NDCG@5   | MRR@5   | PREC@10   | REC@10   | MAP@10   | NDCG@10   |  MRR@10 |\n",
    "|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|\n",
    "| 0.4437 |  0.1106 |  0.3692 |  0.1749 |  0.6578 | 0.3813 |  0.1770 |  0.3003 |  0.2321 |  0.667 |\n",
    "\n",
    "\n",
    "In this paper, the dataset is converted into a implicit dataset, so ratings are either 1 or 0. Evaulation was performed by averaging over five different 80/20 train/test splits. (We will just look at a single split below).\n",
    "\n",
    " The [hyperparameters](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation/blob/861eafeaba2943458adec22469b147ec492784b6/DL_Evaluation_TOIS_Additional_material.pdf) are set as `l1_ratio=1.89e-5` and `alpha=0.049`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ratings.keys():\n",
    "    ratings[key] = (1, ratings[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = SLIM(alpha=0.049, l1_ratio=1.89e-5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs, _ = recommender.recommend(all_contexts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@5: {'PREC': 0.3241721854304636, 'REC': 0.06738210300791221, 'MAP': 0.43651995952906547, 'NDCG': 0.10395269380895251, 'MRR': 0.45423013245033117}\n",
      "@10: {'PREC': 0.3814238410596027, 'REC': 0.17422638615796424, 'MAP': 0.43883045470150284, 'NDCG': 0.18934677631282193, 'MRR': 0.47939562966466936}\n"
     ]
    }
   ],
   "source": [
    "for N in [5, 10]:\n",
    "    res = compute_PREC_REC_MAP_NDCG_MRR(N, users, recs, test_ratings)\n",
    "    print('@{}:'.format(N), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASE\n",
    "\n",
    "In \"A troubling analysis\" (https://arxiv.org/pdf/1911.07698.pdf), EASE achieves the following results on ML 1M\n",
    "\n",
    "\n",
    "\n",
    "| PREC@5   | REC@5   | MAP@5   | NDCG@5   | MRR@5   | PREC@10   | REC@10   | MAP@10   | NDCG@10   |  MRR@10 |\n",
    "|------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|\n",
    "| 0.4360  | 0.1073  | 0.3608  | 0.1697  | 0.6475 | 0.3745  | 0.1731  | 0.2923  | 0.2259  | 0.65| \n",
    " \n",
    "In this paper, the dataset is converted into a implicit dataset, so ratings are either 1 or 0. Evaulation was performed by averaging over five different 80/20 train/test splits. (We will just look at a single split below).\n",
    "\n",
    "The [hyperparameters](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation/blob/861eafeaba2943458adec22469b147ec492784b6/DL_Evaluation_TOIS_Additional_material.pdf) are set as `lam=1.25e3`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')\n",
    "for key in ratings.keys():\n",
    "    ratings[key] = (1, ratings[key][1])\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])\n",
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = EASE(lam=1.25e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs, _ = recommender.recommend(all_contexts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@5: {'PREC': 0.32466887417218543, 'REC': 0.06821147096556184, 'MAP': 0.4329348325974981, 'NDCG': 0.10444392654073191, 'MRR': 0.4466197571743929}\n",
      "@10: {'PREC': 0.38415562913907286, 'REC': 0.17628998806236673, 'MAP': 0.4373985546772671, 'NDCG': 0.19097229149913342, 'MRR': 0.4719510801009146}\n"
     ]
    }
   ],
   "source": [
    "for N in [5, 10]:\n",
    "    res = compute_PREC_REC_MAP_NDCG_MRR(N, users, recs, test_ratings)\n",
    "    print('@{}:'.format(N), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserKNN cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Surprise repo changing the benchmarking script (https://github.com/NicolasHug/Surprise/blob/master/examples/benchmark.py) on KNNWithMeans to use cosine similarity leads to an RMSE of 0.942 on MovieLens 1M.\n",
    "\n",
    "\n",
    "The [hyperparameters](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans) are set as `topK=40`, `shrink=0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[autoreload of reclab.recommenders.top_pop failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 0 free vars, not 1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])\n",
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = KNNRecommender(shrinkage=0, neighborhood_size=40, user_based=True, use_means=True, use_content=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = recommender.dense_predictions\n",
    "t = [(uid, iid, np.zeros(0)) for uid, iid in test_ratings]\n",
    "preds = recommender.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.9458989545474523\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "num = 0.0\n",
    "for (uid, iid, _), pred in zip(t, preds):\n",
    "    tot += (test_ratings[uid, iid][0] - pred) **2\n",
    "    num += 1\n",
    "print(\"RMSE is\", np.sqrt(tot / num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemKNN cosine\n",
    "In the Surprise repo changing the benchmarking script (https://github.com/NicolasHug/Surprise/blob/master/examples/benchmark.py) on KNNWithMeans to use cosine similarity leads to an RMSE of 0.993 on MovieLens 1M.\n",
    "\n",
    "\n",
    "The [hyperparameters](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans) are set as `topK=40`, `shrink=0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])\n",
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = KNNRecommender(shrinkage=0, neighborhood_size=40, user_based=False, use_means=True, use_content=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = recommender.dense_predictions\n",
    "t = [(uid, iid, np.zeros(0)) for uid, iid in test_ratings]\n",
    "preds = recommender.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.8874714464182688\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "num = 0.0\n",
    "for (uid, iid, _), pred in zip(t, preds):\n",
    "    tot += (test_ratings[uid, iid][0] - pred) **2\n",
    "    num += 1\n",
    "print(\"RMSE is\", np.sqrt(tot / num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LibFM MCMC\n",
    "In the baselines paper (https://arxiv.org/pdf/1905.01395.pdf) they report an RMSE of around 0.765 on MovieLens 10M.\n",
    "\n",
    "\n",
    "The [hyperparameters](https://arxiv.org/pdf/1905.01395.pdf) (Section 5.2) are set as `num_two_way_factors=128`, `init_stdev=0.1`, `num_iter=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-10m')\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])\n",
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.9, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = LibFM(num_user_features=0,\n",
    "                    num_item_features=0,\n",
    "                    num_rating_features=0,\n",
    "                    max_num_users=len(users),\n",
    "                    max_num_items=len(items),\n",
    "                    num_two_way_factors=128,\n",
    "                    init_stdev=0.1,\n",
    "                    num_iter=100,\n",
    "                    method='mcmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [(uid, iid, np.zeros(0)) for uid, iid in test_ratings]\n",
    "preds = recommender.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.7659974180103403\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "num = 0.0\n",
    "for (uid, iid, _), pred in zip(t, preds):\n",
    "    tot += (test_ratings[uid, iid][0] - pred) **2\n",
    "    num += 1\n",
    "print(\"RMSE is\", np.sqrt(tot / num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global LLORMA\n",
    "\n",
    "LLORMA (Local Low-Rank Matrix Approximation) http://jmlr.org/papers/volume17/14-301/14-301.pdf is Matrix Factorization ispired method that fits many weighted-MF models and averages over them. Our implementation is based on\n",
    "https://github.com/JoonyoungYi/LLORMA-tensorflow implementation.\n",
    "\n",
    "The hyper-parameter values are\n",
    "    \n",
    "    N_ANCHOR = 10\n",
    "\n",
    "    PRE_RANK = 5\n",
    "    PRE_LEARNING_RATE = 2e-4\n",
    "    PRE_LAMBDA = 10\n",
    "\n",
    "    RANK = 10\n",
    "    LEARNING_RATE = 1e-2\n",
    "    LAMBDA = 1e-3\n",
    "    BATCH_SIZE = 128\n",
    "    \n",
    "They report a performance of 0.930 on ML-100K, we achieve a performance of 0.940\n",
    "(evaluating on ML-1M or ML-10M is prohibitively slow) \n",
    "The original paper for a larger mode (rank=20, n_anchors=100) achieves a loss of 0.899, we get 0.927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-100k')\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])\n",
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_anchor': 10, \n",
    "          'pre_rank': 5, \n",
    "          'pre_learning_rate': 2e-4,\n",
    "          'pre_lambda_val': 10,\n",
    "          'pre_train_steps': 100,\n",
    "          'rank': 10,\n",
    "          'learning_rate': 1e-2,\n",
    "          'lambda_val': 1e-3,\n",
    "          'batch_size': 128,\n",
    "          'train_steps': 50,\n",
    "          'use_cache': True}\n",
    "\n",
    "recommender = Llorma(len(users), len(items), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low: 2.998, Mean: 3.517, High: 3.974\n",
      "RMSE is 0.9406582762937047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../reclab/recommenders/llorma/llorma_lib/llorma_g.py:436: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predict_k[np.isnan(predict_k)] = 0\n"
     ]
    }
   ],
   "source": [
    "t = [(uid, iid, np.zeros(0)) for uid, iid in test_ratings]\n",
    "preds = recommender.predict(t)\n",
    "tot = 0.0\n",
    "num = 0.0\n",
    "for (uid, iid, _), pred in zip(t, preds):\n",
    "    tot += (test_ratings[uid, iid][0] - pred) **2\n",
    "    num += 1\n",
    "print(\"RMSE is\", np.sqrt(tot / num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:167: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/train_utils.py:70: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:194: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:197: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:147: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:298: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:299: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/llorma_g.py:312: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Pre-train step: 0, train_error:1.1149220382440692\n",
      "Pre-train step: 1, train_error:1.040608468333719\n",
      "Pre-train step: 2, train_error:1.02886344730357\n",
      "Pre-train step: 3, train_error:1.0261757078346831\n",
      "Pre-train step: 4, train_error:1.0203726659858003\n",
      "Pre-train step: 5, train_error:1.0144814043905237\n",
      "Pre-train step: 6, train_error:1.0055757959777942\n",
      "Pre-train step: 7, train_error:1.0035250895520307\n",
      "Pre-train step: 8, train_error:1.0073046965451715\n",
      "Pre-train step: 9, train_error:1.003998059966839\n",
      "Pre-train step: 10, train_error:0.9978783185620222\n",
      "Pre-train step: 11, train_error:0.9993548044112733\n",
      "Pre-train step: 12, train_error:1.0020340215033854\n",
      "Pre-train step: 13, train_error:0.9983674234896629\n",
      "Pre-train step: 14, train_error:0.9942409839462831\n",
      "Pre-train step: 15, train_error:0.9945044801009275\n",
      "Pre-train step: 16, train_error:0.9945314167835009\n",
      "Pre-train step: 17, train_error:0.9911064290344258\n",
      "Pre-train step: 18, train_error:0.9872255182457897\n",
      "Pre-train step: 19, train_error:0.9850050520795061\n",
      "Pre-train step: 20, train_error:0.9829992586031979\n",
      "Pre-train step: 21, train_error:0.9803839334384475\n",
      "Pre-train step: 22, train_error:0.9780088560381957\n",
      "Pre-train step: 23, train_error:0.9759665481334312\n",
      "Pre-train step: 24, train_error:0.9734827008885801\n",
      "Pre-train step: 25, train_error:0.9706289427072832\n",
      "Pre-train step: 26, train_error:0.968298359586883\n",
      "Pre-train step: 27, train_error:0.9667513391854444\n",
      "Pre-train step: 28, train_error:0.9652957079753686\n",
      "Pre-train step: 29, train_error:0.9634848275759634\n",
      "Pre-train step: 30, train_error:0.9617059332190621\n",
      "Pre-train step: 31, train_error:0.9602373549795585\n",
      "Pre-train step: 32, train_error:0.9587099246194706\n",
      "Pre-train step: 33, train_error:0.9569896521851003\n",
      "Pre-train step: 34, train_error:0.9555177909319333\n",
      "Pre-train step: 35, train_error:0.9543862386308322\n",
      "Pre-train step: 36, train_error:0.9531762725766376\n",
      "Pre-train step: 37, train_error:0.9518014748515028\n",
      "Pre-train step: 38, train_error:0.9505060340062529\n",
      "Pre-train step: 39, train_error:0.9492662321756768\n",
      "Pre-train step: 40, train_error:0.947934241036765\n",
      "Pre-train step: 41, train_error:0.9465338630700891\n",
      "Pre-train step: 42, train_error:0.9450717551610869\n",
      "Pre-train step: 43, train_error:0.9435460566549626\n",
      "Pre-train step: 44, train_error:0.9420778128106997\n",
      "Pre-train step: 45, train_error:0.9406374291548146\n",
      "Pre-train step: 46, train_error:0.9390011605997931\n",
      "Pre-train step: 47, train_error:0.9371887155666202\n",
      "Pre-train step: 48, train_error:0.9354435889034494\n",
      "Pre-train step: 49, train_error:0.9337655236579763\n",
      "Pre-train step: 50, train_error:0.9319650359938121\n",
      "Pre-train step: 51, train_error:0.9300656932432965\n",
      "Pre-train step: 52, train_error:0.928241585366523\n",
      "Pre-train step: 53, train_error:0.9265184853263199\n",
      "Pre-train step: 54, train_error:0.9248128511173123\n",
      "Pre-train step: 55, train_error:0.9231053367366803\n",
      "Pre-train step: 56, train_error:0.9214141865933426\n",
      "Pre-train step: 57, train_error:0.9197224414325318\n",
      "Pre-train step: 58, train_error:0.9180163449801998\n",
      "Pre-train step: 59, train_error:0.916325641364602\n",
      "Pre-train step: 60, train_error:0.9146945739435038\n",
      "Pre-train step: 61, train_error:0.9131420724149674\n",
      "Pre-train step: 62, train_error:0.9116535186755497\n",
      "Pre-train step: 63, train_error:0.9102018894197772\n",
      "Pre-train step: 64, train_error:0.9087735278047497\n",
      "Pre-train step: 65, train_error:0.9073659161526959\n",
      "Pre-train step: 66, train_error:0.9059698523974361\n",
      "Pre-train step: 67, train_error:0.9045770651851174\n",
      "Pre-train step: 68, train_error:0.9032004171466537\n",
      "Pre-train step: 69, train_error:0.9018641800594415\n",
      "Pre-train step: 70, train_error:0.9005793577071687\n",
      "Pre-train step: 71, train_error:0.899345705143635\n",
      "Pre-train step: 72, train_error:0.8981679609255272\n",
      "Pre-train step: 73, train_error:0.8970515366197159\n",
      "Pre-train step: 74, train_error:0.8959887674952745\n",
      "Pre-train step: 75, train_error:0.8949638267034894\n",
      "Pre-train step: 76, train_error:0.8939677711829316\n",
      "Pre-train step: 77, train_error:0.8930011662162423\n",
      "Pre-train step: 78, train_error:0.892066972215816\n",
      "Pre-train step: 79, train_error:0.8911671993646767\n",
      "Pre-train step: 80, train_error:0.8903032029271785\n",
      "Pre-train step: 81, train_error:0.8894743202235917\n",
      "Pre-train step: 82, train_error:0.8886762647929235\n",
      "Pre-train step: 83, train_error:0.8879020147316449\n",
      "Pre-train step: 84, train_error:0.8871451897410864\n",
      "Pre-train step: 85, train_error:0.8864048724870102\n",
      "Pre-train step: 86, train_error:0.8856880226886836\n",
      "Pre-train step: 87, train_error:0.8850051395405725\n",
      "Pre-train step: 88, train_error:0.8843623917202809\n",
      "Pre-train step: 89, train_error:0.8837582178683048\n",
      "Pre-train step: 90, train_error:0.8831857055689186\n",
      "Pre-train step: 91, train_error:0.8826360739596216\n",
      "Pre-train step: 92, train_error:0.8821020215297565\n",
      "Pre-train step: 93, train_error:0.8815816805556284\n",
      "Pre-train step: 94, train_error:0.8810796655725985\n",
      "Pre-train step: 95, train_error:0.8806025775906251\n",
      "Pre-train step: 96, train_error:0.880153552966678\n",
      "Pre-train step: 97, train_error:0.8797311227661309\n",
      "Pre-train step: 98, train_error:0.8793311151279871\n",
      "Pre-train step: 99, train_error:0.8789485020328268\n",
      "INFO:tensorflow:Restoring parameters from results/pre-model-403909.ckpt\n",
      "WARNING:tensorflow:From ../reclab/recommenders/llorma/llorma_lib/train_utils.py:24: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Train step:0\n",
      "Train step:0, train error: 1.0870501356185382, test error: 1.0870501356185382\n",
      "INFO:tensorflow:Restoring parameters from results/model-0.ckpt\n",
      "Train step:1\n",
      "Train step:1, train error: 1.0590313848607025, test error: 1.0590313848607025\n",
      "INFO:tensorflow:Restoring parameters from results/model-1.ckpt\n",
      "Train step:2\n",
      "Train step:2, train error: 1.0384147925680876, test error: 1.0384147925680876\n",
      "INFO:tensorflow:Restoring parameters from results/model-2.ckpt\n",
      "Train step:3\n",
      "Train step:3, train error: 1.022675739520288, test error: 1.022675739520288\n",
      "INFO:tensorflow:Restoring parameters from results/model-3.ckpt\n",
      "Train step:4\n",
      "Train step:4, train error: 1.0102832587037727, test error: 1.0102832587037727\n",
      "INFO:tensorflow:Restoring parameters from results/model-4.ckpt\n",
      "Train step:5\n",
      "Train step:5, train error: 1.0002705290487068, test error: 1.0002705290487068\n",
      "WARNING:tensorflow:From /Users/mcurmei/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from results/model-5.ckpt\n",
      "Train step:6\n",
      "Train step:6, train error: 0.9920027034640524, test error: 0.9920027034640524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from results/model-6.ckpt\n",
      "Train step:7\n",
      "Train step:7, train error: 0.9850480174413682, test error: 0.9850480174413682\n",
      "INFO:tensorflow:Restoring parameters from results/model-7.ckpt\n",
      "Train step:8\n",
      "Train step:8, train error: 0.9791037480869652, test error: 0.9791037480869652\n",
      "INFO:tensorflow:Restoring parameters from results/model-8.ckpt\n",
      "Train step:9\n",
      "Train step:9, train error: 0.9739520627014345, test error: 0.9739520627014345\n",
      "INFO:tensorflow:Restoring parameters from results/model-9.ckpt\n",
      "Train step:10\n",
      "Train step:10, train error: 0.9694326977659745, test error: 0.9694326977659745\n",
      "INFO:tensorflow:Restoring parameters from results/model-10.ckpt\n",
      "Train step:11\n",
      "Train step:11, train error: 0.9654254628305714, test error: 0.9654254628305714\n",
      "INFO:tensorflow:Restoring parameters from results/model-11.ckpt\n",
      "Train step:12\n",
      "Train step:12, train error: 0.9618386906289095, test error: 0.9618386906289095\n",
      "INFO:tensorflow:Restoring parameters from results/model-12.ckpt\n",
      "Train step:13\n",
      "Train step:13, train error: 0.9586014097589853, test error: 0.9586014097589853\n",
      "INFO:tensorflow:Restoring parameters from results/model-13.ckpt\n",
      "Train step:14\n",
      "Train step:14, train error: 0.95565791942195, test error: 0.95565791942195\n",
      "INFO:tensorflow:Restoring parameters from results/model-14.ckpt\n",
      "Train step:15\n",
      "Train step:15, train error: 0.9529639554989583, test error: 0.9529639554989583\n",
      "INFO:tensorflow:Restoring parameters from results/model-15.ckpt\n",
      "Train step:16\n",
      "Train step:16, train error: 0.9504839350455646, test error: 0.9504839350455646\n",
      "INFO:tensorflow:Restoring parameters from results/model-16.ckpt\n",
      "Train step:17\n",
      "Train step:17, train error: 0.9481889460354898, test error: 0.9481889460354898\n",
      "INFO:tensorflow:Restoring parameters from results/model-17.ckpt\n",
      "Train step:18\n",
      "Train step:18, train error: 0.9460552609627167, test error: 0.9460552609627167\n",
      "INFO:tensorflow:Restoring parameters from results/model-18.ckpt\n",
      "Train step:19\n",
      "Train step:19, train error: 0.9440632242665064, test error: 0.9440632242665064\n",
      "INFO:tensorflow:Restoring parameters from results/model-19.ckpt\n",
      "Train step:20\n",
      "Train step:20, train error: 0.9421964101443918, test error: 0.9421964101443918\n",
      "INFO:tensorflow:Restoring parameters from results/model-20.ckpt\n",
      "Train step:21\n",
      "Train step:21, train error: 0.9404409783570593, test error: 0.9404409783570593\n",
      "INFO:tensorflow:Restoring parameters from results/model-21.ckpt\n",
      "Train step:22\n",
      "Train step:22, train error: 0.9387851766606937, test error: 0.9387851766606937\n",
      "INFO:tensorflow:Restoring parameters from results/model-22.ckpt\n",
      "Train step:23\n",
      "Train step:23, train error: 0.9372189529709242, test error: 0.9372189529709242\n",
      "INFO:tensorflow:Restoring parameters from results/model-23.ckpt\n",
      "Train step:24\n",
      "Train step:24, train error: 0.9357336504522624, test error: 0.9357336504522624\n",
      "INFO:tensorflow:Restoring parameters from results/model-24.ckpt\n",
      "Train step:25\n",
      "Train step:25, train error: 0.9343217658507416, test error: 0.9343217658507416\n",
      "INFO:tensorflow:Restoring parameters from results/model-25.ckpt\n",
      "Train step:26\n",
      "Train step:26, train error: 0.932976756474917, test error: 0.932976756474917\n",
      "INFO:tensorflow:Restoring parameters from results/model-26.ckpt\n",
      "Train step:27\n",
      "Train step:27, train error: 0.9316928849023585, test error: 0.9316928849023585\n",
      "INFO:tensorflow:Restoring parameters from results/model-27.ckpt\n",
      "Train step:28\n",
      "Train step:28, train error: 0.930465093165571, test error: 0.930465093165571\n",
      "INFO:tensorflow:Restoring parameters from results/model-28.ckpt\n",
      "Train step:29\n",
      "Train step:29, train error: 0.9292889001409417, test error: 0.9292889001409417\n",
      "INFO:tensorflow:Restoring parameters from results/model-29.ckpt\n",
      "Train step:30\n",
      "Train step:30, train error: 0.9281603173264897, test error: 0.9281603173264897\n",
      "INFO:tensorflow:Restoring parameters from results/model-30.ckpt\n",
      "Train step:31\n",
      "Train step:31, train error: 0.9270757792886881, test error: 0.9270757792886881\n",
      "INFO:tensorflow:Restoring parameters from results/model-31.ckpt\n",
      "Train step:32\n",
      "Train step:32, train error: 0.9260320858843761, test error: 0.9260320858843761\n",
      "INFO:tensorflow:Restoring parameters from results/model-32.ckpt\n",
      "Train step:33\n",
      "Train step:33, train error: 0.9250263539914165, test error: 0.9250263539914165\n",
      "INFO:tensorflow:Restoring parameters from results/model-33.ckpt\n",
      "Train step:34\n",
      "Train step:34, train error: 0.9240559769621657, test error: 0.9240559769621657\n",
      "INFO:tensorflow:Restoring parameters from results/model-34.ckpt\n",
      "Train step:35\n",
      "Train step:35, train error: 0.9231185903840291, test error: 0.9231185903840291\n",
      "INFO:tensorflow:Restoring parameters from results/model-35.ckpt\n",
      "Train step:36\n",
      "Train step:36, train error: 0.922212043018431, test error: 0.922212043018431\n",
      "INFO:tensorflow:Restoring parameters from results/model-36.ckpt\n",
      "Train step:37\n",
      "Train step:37, train error: 0.9213343720134894, test error: 0.9213343720134894\n",
      "INFO:tensorflow:Restoring parameters from results/model-37.ckpt\n",
      "Train step:38\n",
      "Train step:38, train error: 0.9204837816613897, test error: 0.9204837816613897\n",
      "INFO:tensorflow:Restoring parameters from results/model-38.ckpt\n",
      "Train step:39\n",
      "Train step:39, train error: 0.9196586251100718, test error: 0.9196586251100718\n",
      "INFO:tensorflow:Restoring parameters from results/model-39.ckpt\n",
      "Train step:40\n",
      "Train step:40, train error: 0.9188573885487782, test error: 0.9188573885487782\n",
      "INFO:tensorflow:Restoring parameters from results/model-40.ckpt\n",
      "Train step:41\n",
      "Train step:41, train error: 0.9180786774746149, test error: 0.9180786774746149\n",
      "INFO:tensorflow:Restoring parameters from results/model-41.ckpt\n",
      "Train step:42\n",
      "Train step:42, train error: 0.9173212047174574, test error: 0.9173212047174574\n",
      "INFO:tensorflow:Restoring parameters from results/model-42.ckpt\n",
      "Train step:43\n",
      "Train step:43, train error: 0.916583779956972, test error: 0.916583779956972\n",
      "INFO:tensorflow:Restoring parameters from results/model-43.ckpt\n",
      "Train step:44\n",
      "Train step:44, train error: 0.9158653005111667, test error: 0.9158653005111667\n",
      "INFO:tensorflow:Restoring parameters from results/model-44.ckpt\n",
      "Train step:45\n",
      "Train step:45, train error: 0.9151647432129041, test error: 0.9151647432129041\n",
      "INFO:tensorflow:Restoring parameters from results/model-45.ckpt\n",
      "Train step:46\n",
      "Train step:46, train error: 0.914481157221015, test error: 0.914481157221015\n",
      "INFO:tensorflow:Restoring parameters from results/model-46.ckpt\n",
      "Train step:47\n",
      "Train step:47, train error: 0.9138136576373443, test error: 0.9138136576373443\n",
      "INFO:tensorflow:Restoring parameters from results/model-47.ckpt\n",
      "Train step:48\n",
      "Train step:48, train error: 0.9131614198213804, test error: 0.9131614198213804\n",
      "INFO:tensorflow:Restoring parameters from results/model-48.ckpt\n",
      "Train step:49\n",
      "Train step:49, train error: 0.9125236743108592, test error: 0.9125236743108592\n",
      "INFO:tensorflow:Restoring parameters from results/model-49.ckpt\n",
      "Train step:50\n",
      "Train step:50, train error: 0.9118997022706159, test error: 0.9118997022706159\n",
      "INFO:tensorflow:Restoring parameters from results/model-50.ckpt\n",
      "Train step:51\n",
      "Train step:51, train error: 0.9112888314034767, test error: 0.9112888314034767\n",
      "INFO:tensorflow:Restoring parameters from results/model-51.ckpt\n",
      "Train step:52\n",
      "Train step:52, train error: 0.9106904322666112, test error: 0.9106904322666112\n",
      "INFO:tensorflow:Restoring parameters from results/model-52.ckpt\n",
      "Train step:53\n",
      "Train step:53, train error: 0.9101039149448161, test error: 0.9101039149448161\n",
      "INFO:tensorflow:Restoring parameters from results/model-53.ckpt\n",
      "Train step:54\n",
      "Train step:54, train error: 0.9095287260389641, test error: 0.9095287260389641\n",
      "INFO:tensorflow:Restoring parameters from results/model-54.ckpt\n",
      "Train step:55\n",
      "Train step:55, train error: 0.9089643459335579, test error: 0.9089643459335579\n",
      "INFO:tensorflow:Restoring parameters from results/model-55.ckpt\n",
      "Train step:56\n",
      "Train step:56, train error: 0.9084102863121565, test error: 0.9084102863121565\n",
      "INFO:tensorflow:Restoring parameters from results/model-56.ckpt\n",
      "Train step:57\n",
      "Train step:57, train error: 0.9078660878935302, test error: 0.9078660878935302\n",
      "INFO:tensorflow:Restoring parameters from results/model-57.ckpt\n",
      "Train step:58\n",
      "Train step:58, train error: 0.9073313183648896, test error: 0.9073313183648896\n",
      "INFO:tensorflow:Restoring parameters from results/model-58.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step:59\n",
      "Train step:59, train error: 0.906805570491514, test error: 0.906805570491514\n",
      "INFO:tensorflow:Restoring parameters from results/model-59.ckpt\n",
      "Train step:60\n",
      "Train step:60, train error: 0.9062884603846499, test error: 0.9062884603846499\n",
      "INFO:tensorflow:Restoring parameters from results/model-60.ckpt\n",
      "Train step:61\n",
      "Train step:61, train error: 0.9057796259117463, test error: 0.9057796259117463\n",
      "INFO:tensorflow:Restoring parameters from results/model-61.ckpt\n",
      "Train step:62\n",
      "Train step:62, train error: 0.9052787252349825, test error: 0.9052787252349825\n",
      "INFO:tensorflow:Restoring parameters from results/model-62.ckpt\n",
      "Train step:63\n",
      "Train step:63, train error: 0.9047854354656772, test error: 0.9047854354656772\n",
      "INFO:tensorflow:Restoring parameters from results/model-63.ckpt\n",
      "Train step:64\n",
      "Train step:64, train error: 0.9042994514235809, test error: 0.9042994514235809\n",
      "INFO:tensorflow:Restoring parameters from results/model-64.ckpt\n",
      "Train step:65\n",
      "Train step:65, train error: 0.903820484491288, test error: 0.903820484491288\n",
      "INFO:tensorflow:Restoring parameters from results/model-65.ckpt\n",
      "Train step:66\n",
      "Train step:66, train error: 0.9033482615550762, test error: 0.9033482615550762\n",
      "INFO:tensorflow:Restoring parameters from results/model-66.ckpt\n",
      "Train step:67\n",
      "Train step:67, train error: 0.902882524024413, test error: 0.902882524024413\n",
      "INFO:tensorflow:Restoring parameters from results/model-67.ckpt\n",
      "Train step:68\n",
      "Train step:68, train error: 0.9024230269232019, test error: 0.9024230269232019\n",
      "INFO:tensorflow:Restoring parameters from results/model-68.ckpt\n",
      "Train step:69\n",
      "Train step:69, train error: 0.9019695380465456, test error: 0.9019695380465456\n",
      "INFO:tensorflow:Restoring parameters from results/model-69.ckpt\n",
      "Train step:70\n",
      "Train step:70, train error: 0.9015218371774545, test error: 0.9015218371774545\n",
      "INFO:tensorflow:Restoring parameters from results/model-70.ckpt\n",
      "Train step:71\n",
      "Train step:71, train error: 0.9010797153584764, test error: 0.9010797153584764\n",
      "INFO:tensorflow:Restoring parameters from results/model-71.ckpt\n",
      "Train step:72\n",
      "Train step:72, train error: 0.900642974213727, test error: 0.900642974213727\n",
      "INFO:tensorflow:Restoring parameters from results/model-72.ckpt\n",
      "Train step:73\n",
      "Train step:73, train error: 0.9002114253172319, test error: 0.9002114253172319\n",
      "INFO:tensorflow:Restoring parameters from results/model-73.ckpt\n",
      "Train step:74\n",
      "Train step:74, train error: 0.8997848896038895, test error: 0.8997848896038895\n",
      "INFO:tensorflow:Restoring parameters from results/model-74.ckpt\n",
      "Train step:75\n",
      "Train step:75, train error: 0.8993631968197042, test error: 0.8993631968197042\n",
      "INFO:tensorflow:Restoring parameters from results/model-75.ckpt\n",
      "Train step:76\n",
      "Train step:76, train error: 0.8989461850082507, test error: 0.8989461850082507\n",
      "INFO:tensorflow:Restoring parameters from results/model-76.ckpt\n",
      "Train step:77\n",
      "Train step:77, train error: 0.8985337000306078, test error: 0.8985337000306078\n",
      "INFO:tensorflow:Restoring parameters from results/model-77.ckpt\n",
      "Train step:78\n",
      "Train step:78, train error: 0.8981255951162471, test error: 0.8981255951162471\n",
      "INFO:tensorflow:Restoring parameters from results/model-78.ckpt\n",
      "Train step:79\n",
      "Train step:79, train error: 0.8977217304425821, test error: 0.8977217304425821\n",
      "INFO:tensorflow:Restoring parameters from results/model-79.ckpt\n",
      "Train step:80\n",
      "Train step:80, train error: 0.8973219727410863, test error: 0.8973219727410863\n",
      "INFO:tensorflow:Restoring parameters from results/model-80.ckpt\n",
      "Train step:81\n",
      "Train step:81, train error: 0.8969261949280612, test error: 0.8969261949280612\n",
      "INFO:tensorflow:Restoring parameters from results/model-81.ckpt\n",
      "Train step:82\n",
      "Train step:82, train error: 0.8965342757583078, test error: 0.8965342757583078\n",
      "INFO:tensorflow:Restoring parameters from results/model-82.ckpt\n",
      "Train step:83\n",
      "Train step:83, train error: 0.896146099500086, test error: 0.896146099500086\n",
      "INFO:tensorflow:Restoring parameters from results/model-83.ckpt\n",
      "Train step:84\n",
      "Train step:84, train error: 0.8957615556298959, test error: 0.8957615556298959\n",
      "INFO:tensorflow:Restoring parameters from results/model-84.ckpt\n",
      "Train step:85\n",
      "Train step:85, train error: 0.895380538545717, test error: 0.895380538545717\n",
      "INFO:tensorflow:Restoring parameters from results/model-85.ckpt\n",
      "Train step:86\n",
      "Train step:86, train error: 0.8950029472974621, test error: 0.8950029472974621\n",
      "INFO:tensorflow:Restoring parameters from results/model-86.ckpt\n",
      "Train step:87\n",
      "Train step:87, train error: 0.8946286853334942, test error: 0.8946286853334942\n",
      "INFO:tensorflow:Restoring parameters from results/model-87.ckpt\n",
      "Train step:88\n",
      "Train step:88, train error: 0.8942576602621474, test error: 0.8942576602621474\n",
      "INFO:tensorflow:Restoring parameters from results/model-88.ckpt\n",
      "Train step:89\n",
      "Train step:89, train error: 0.8938897836272708, test error: 0.8938897836272708\n",
      "INFO:tensorflow:Restoring parameters from results/model-89.ckpt\n",
      "Train step:90\n",
      "Train step:90, train error: 0.8935249706968924, test error: 0.8935249706968924\n",
      "INFO:tensorflow:Restoring parameters from results/model-90.ckpt\n",
      "Train step:91\n",
      "Train step:91, train error: 0.8931631402641633, test error: 0.8931631402641633\n",
      "INFO:tensorflow:Restoring parameters from results/model-91.ckpt\n",
      "Train step:92\n",
      "Train step:92, train error: 0.8928042144598083, test error: 0.8928042144598083\n",
      "INFO:tensorflow:Restoring parameters from results/model-92.ckpt\n",
      "Train step:93\n",
      "Train step:93, train error: 0.892448118575361, test error: 0.892448118575361\n",
      "INFO:tensorflow:Restoring parameters from results/model-93.ckpt\n",
      "Train step:94\n",
      "Train step:94, train error: 0.892094780896518, test error: 0.892094780896518\n",
      "INFO:tensorflow:Restoring parameters from results/model-94.ckpt\n",
      "Train step:95\n",
      "Train step:95, train error: 0.8917441325459908, test error: 0.8917441325459908\n",
      "INFO:tensorflow:Restoring parameters from results/model-95.ckpt\n",
      "Train step:96\n",
      "Train step:96, train error: 0.8913961073352759, test error: 0.8913961073352759\n",
      "INFO:tensorflow:Restoring parameters from results/model-96.ckpt\n",
      "Train step:97\n",
      "Train step:97, train error: 0.8910506416248104, test error: 0.8910506416248104\n",
      "INFO:tensorflow:Restoring parameters from results/model-97.ckpt\n",
      "Train step:98\n",
      "Train step:98, train error: 0.8907076741920096, test error: 0.8907076741920096\n",
      "INFO:tensorflow:Restoring parameters from results/model-98.ckpt\n",
      "Train step:99\n",
      "Train step:99, train error: 0.8903671461067186, test error: 0.8903671461067186\n",
      "INFO:tensorflow:Restoring parameters from results/model-99.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Model with 100 local models\n",
    "params = {'n_anchor': 100, \n",
    "          'pre_rank': 5, \n",
    "          'pre_learning_rate': 2e-4,\n",
    "          'pre_lambda_val': 10,\n",
    "          'pre_train_steps': 100,\n",
    "          'rank': 20,\n",
    "          'learning_rate': 1e-2,\n",
    "          'lambda_val': 1e-3,\n",
    "          'batch_size': 1000,\n",
    "          'train_steps': 100,\n",
    "          'use_cache': True}\n",
    "\n",
    "recommender = Llorma(len(users), len(items), **params)\n",
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low: 3.032, Mean: 3.489, High: 3.902\n",
      "RMSE is 0.9274755234532681\n"
     ]
    }
   ],
   "source": [
    "t = [(uid, iid, np.zeros(0)) for uid, iid in test_ratings]\n",
    "preds = recommender.predict(t)\n",
    "tot = 0.0\n",
    "num = 0.0\n",
    "for (uid, iid, _), pred in zip(t, preds):\n",
    "    tot += (test_ratings[uid, iid][0] - pred) **2\n",
    "    num += 1\n",
    "print(\"RMSE is\", np.sqrt(tot / num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1.4",
   "language": "python",
   "name": "tensorflow1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
