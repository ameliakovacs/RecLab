{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "import run_utils\n",
    "\n",
    "sys.path.append('../') \n",
    "import reclab\n",
    "\n",
    "from reclab.recommenders import SLIM, EASE\n",
    "from reclab import data_utils\n",
    "\n",
    "sys.path.append('../tests') \n",
    "import utils\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hr_ndcg(N, users, recs, test_ratings):\n",
    "    assert recs.shape[1] >= N\n",
    "    num_hits = 0\n",
    "    cdg = 0\n",
    "    for user_id, rec in zip(users, recs):\n",
    "        for i,r in enumerate(rec[:N]):\n",
    "            if (user_id, r) in test_ratings:\n",
    "                value = test_ratings[(user_id, r)][0]\n",
    "                cdg += value * np.log(2) / np.log(i+2)\n",
    "                num_hits += value\n",
    "    return num_hits / len(users) / N, cdg / len(users) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIM\n",
    "\n",
    "In \"A troubling analysis\" (https://arxiv.org/pdf/1911.07698.pdf), SLIM achieves the following results on ML 1M\n",
    "\n",
    "| HR@1   | NDCG@1   | HR@5   |      NDCG@5      |  HR@10 | NDCG@10|\n",
    "|----------|:-------------:|------:|------:|------:|------:|\n",
    "| 0.2207 | 0.2207 | 0.5576 |  0.3953 | 0.7162 | 0.4468 |\n",
    "\n",
    "\n",
    "In this paper, the dataset is converted into a implicit dataset, so ratings are either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in ratings.keys():\n",
    "    ratings[key] = (1, ratings[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to ask about best hyperparameters! (or run code to find)\n",
    "recommender = SLIM(alpha=0.1, l1_ratio=1e-3, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 772.2034709453583, super: 13.336290121078491, tolil: 0.32517457008361816, toarray(x3706): 0.006170749664306641, fit(x3706):0.17826056480407715, loop time:757.6870028972626, csr:0.854973554611206\n"
     ]
    }
   ],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs, _ = recommender.recommend(all_contexts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@1: 0.3675496688741722\n",
      "HR@5: 0.4388079470198676\n",
      "NCDG@5: 0.2477166317962122\n"
     ]
    }
   ],
   "source": [
    "for N in [1, 5, 10]:\n",
    "    hr, ndcg = compute_hr_ndcg(N, users, recs, test_ratings)\n",
    "    print('HR@{}: {}, NCDG@{}: {}'.format(N, hr, N, ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = SLIM(alpha=0.1, l1_ratio=1e-3, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "total: 28.832359313964844, super: 0.8893601894378662, tolil: 0.017225980758666992, toarray(x1682): 0.0008440017700195312, fit(x1682):0.012163877487182617, loop time:27.833446264266968, csr:0.09229564666748047\n",
      "2\n",
      "3\n",
      "total: 29.638110160827637, super: 0.6489026546478271, tolil: 0.018927812576293945, toarray(x1682): 0.0006875991821289062, fit(x1682):0.010415792465209961, loop time:28.88001012802124, csr:0.09023499488830566\n",
      "4\n",
      "total: 42.47570466995239, super: 0.585723876953125, tolil: 0.0322873592376709, toarray(x1682): 0.0009162425994873047, fit(x1682):0.022894620895385742, loop time:41.744932651519775, csr:0.11272811889648438\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "utils.test_binary_recommend_ml100k(recommender, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASE\n",
    "\n",
    "In \"A troubling analysis\" (https://arxiv.org/pdf/1911.07698.pdf), EASE achieves the following results on ML 1M\n",
    "\n",
    "| HR@1   | NDCG@1   | HR@5   |      NDCG@5      |  HR@10 | NDCG@10|\n",
    "|----------|:-------------:|------:|------:|------:|------:|\n",
    "| 0.2119 | 0.2119 | 0.5502 |  0.3857 | 0.7098 | 0.4374 |\n",
    "\n",
    "\n",
    "In this paper, the dataset is converted into a implicit dataset, so ratings are either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, ratings = data_utils.read_dataset('ml-1m')\n",
    "for key in ratings.keys():\n",
    "    ratings[key] = (1, ratings[key][1])\n",
    "all_contexts = collections.OrderedDict([(user_id, np.zeros(0)) for user_id in users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = data_utils.split_ratings(ratings, 0.8, shuffle=True, seed=0)\n",
    "# TODO: need to ask about best hyperparameters! (or run code to find)\n",
    "recommender = EASE(lam=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "recommender.reset(users, items, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs, _ = recommender.recommend(all_contexts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@1: 0.29205298013245035, NCDG@1: 0.29205298013245035\n",
      "HR@5: 0.31728476821192053, NCDG@5: 0.18321577048841534\n",
      "HR@10: 0.380182119205298, NCDG@10: 0.1616521340642658\n"
     ]
    }
   ],
   "source": [
    "for N in [1, 5, 10]:\n",
    "    hr, ndcg = compute_hr_ndcg(N, users, recs, test_ratings)\n",
    "    print('HR@{}: {}, NCDG@{}: {}'.format(N, hr, N, ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
